{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh6DuzEs0cW6",
        "outputId": "0d68cfb6-259f-4d85-d40d-710319870c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "soccer\n"
          ]
        }
      ],
      "source": [
        "# Load Data from interests file csv\n",
        "import pandas as pd\n",
        "\n",
        "categs = [\"Sports\",\t\"Music\",\t\"Art and Creativity\",\t\"Travel\",\t\"Technology and Gaming\"\t,\"Life Style\",\t\"Food & Cooking\",\t\"Volunteer\"]\n",
        "interests_data = pd.read_csv('sample_data/interests.csv',names = categs,header=None)\n",
        "\n",
        "print(interests_data.loc[3]['Sports'])\n",
        "#print(interests_data.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4hQKZx7sGao",
        "outputId": "301fc993-7644-4508-9e6a-dd45f41f577a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__annotations__', '__class__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_map_provider_method', '_select_factory', '_select_factory_choice', '_select_factory_distribution', 'cache_pattern', 'factories', 'generator_attrs', 'items', 'locales', 'random', 'seed', 'seed_instance', 'seed_locale', 'unique', 'weights']\n"
          ]
        }
      ],
      "source": [
        "# For training such models we need synthetic data\n",
        "#!pip install Faker\n",
        "from faker import Faker\n",
        "import random\n",
        "fake = Faker()\n",
        "fake.name()\n",
        "print(dir(Faker))\n",
        "# All we care about users\n",
        "# What and how data are gonna be put inside csv? like for interests and stuff\n",
        "# Coordinates belong to users insitutes\n",
        "user_cols = ['int1','int2','int3','int4','int5','age','coordX','coordY']\n",
        "insts_cols = ['uni','inst','x','y']\n",
        "\n",
        "inst_data = pd.read_csv('sample_data/insts.csv',names = insts_cols,header = None)\n",
        "inst_data\n",
        "# Fake users and put them into csv\n",
        "data = {'int1':'football','int2':'classical','int3':'photography','int4':'backpacking','int5':'video games','age':22,'coordX':'35.764433072675885','coordY':'10.84075666747697'}\n",
        "df = pd.DataFrame([data])\n",
        "for x in range(1000):\n",
        "  # open interest folder and get random interests to put in the dictionary\n",
        "  selected_interests = [\n",
        "      random.choice(interests_data['Sports']),\n",
        "      random.choice(interests_data['Music']),\n",
        "      random.choice(interests_data['Art and Creativity']),\n",
        "      random.choice(interests_data['Travel']),\n",
        "      random.choice(interests_data['Technology and Gaming']),\n",
        "      ]\n",
        "  row = random.choice(range(len(inst_data)))\n",
        "\n",
        "  new_row = pd.DataFrame({\n",
        "                  'int1':[selected_interests[0]],\n",
        "                  'int2':[selected_interests[1]],\n",
        "                  'int3':[selected_interests[2]],\n",
        "                  'int4':[selected_interests[3]],\n",
        "                  'int5':[selected_interests[4]],\n",
        "                  'age':[random.choice(range(19,25))],\n",
        "                  'coordX':[inst_data.loc[row]['x']],\n",
        "                  'coordY':[inst_data.loc[row]['y']]\n",
        "                  })\n",
        "  #print(row)\n",
        "  df = pd.concat([df, new_row], ignore_index=True)\n",
        "  #print(inst_data.loc[row])\n",
        "  #print(inst_data.loc[row]['y'])\n",
        "\n",
        "#print(inst_data.loc[1]['x'])\n",
        "#print(inst_data.loc[1]['y'])\n",
        "#print(df)\n",
        "\n",
        "df.to_csv('sample_data/synth_users.csv', mode='w', header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMXEZQErmZJS"
      },
      "outputs": [],
      "source": [
        "# CollaborativeFiltering with KNN\n",
        "# Version with Insitute Geolocation\n",
        "# User data should include institutes Geo-coordinates within the DataFrame\n",
        "# Facilitate the complexity ; as if the coordinates were the users coordinates no?\n",
        "# If distance is 0 then users belong to the same Institute and of course both should be recommended to each others\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "class CollaborativeFilteringModel:\n",
        "    def __init__(self, user_interests, user_locations, institutes, max_distance=2.0, K=2):\n",
        "        self.user_interests = user_interests\n",
        "        self.user_locations = user_locations\n",
        "        self.institutes = institutes\n",
        "        self.max_distance = max_distance\n",
        "        self.K = K\n",
        "        self.similarity_matrix = None\n",
        "        self.knn_model = None\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        # Calculate cosine similarity matrix\n",
        "        self.similarity_matrix = cosine_similarity(self.user_interests)\n",
        "\n",
        "        # Initialize KNN model\n",
        "        self.knn_model = NearestNeighbors(n_neighbors=self.K, metric='cosine')\n",
        "        self.knn_model.fit(self.user_interests)\n",
        "\n",
        "    def generate_recommendations(self, user_index):\n",
        "        user = self.user_interests[user_index]\n",
        "        _, indices = self.knn_model.kneighbors([user])\n",
        "\n",
        "        recommendations = []\n",
        "        user_location = self.user_locations[user_index]\n",
        "\n",
        "        for idx in indices[0]:\n",
        "            neighbor_user = self.user_interests[idx]\n",
        "            neighbor_location = self.user_locations[idx]\n",
        "\n",
        "            # Check geolocation proximity\n",
        "            distance = geodesic(user_location, neighbor_location).km\n",
        "            if distance <= self.max_distance:\n",
        "                common_interests = np.logical_and(user, neighbor_user)\n",
        "                recommended_users = np.where(common_interests)[0]\n",
        "                recommendations.extend(recommended_users)\n",
        "\n",
        "        return list(set(recommendations))  # Remove duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg7GpdKko6qc"
      },
      "outputs": [],
      "source": [
        "# Following Section is for exploiting the preceding code\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Read the user data from the CSV file\n",
        "user_data = pd.read_csv('sample_data/synth_users.csv')\n",
        "\n",
        "# Extract the necessary information from the user data\n",
        "user_interests = user_data.iloc[:, 1:].values  # Assuming interests start from column index 1\n",
        "user_locations = user_data[['Latitude', 'Longitude']].values\n",
        "institute = user_data['Institute'].values\n",
        "\n",
        "# Calculate the geolocation distance matrix\n",
        "distance_matrix = np.zeros((len(user_locations), len(user_locations)))\n",
        "for i, location1 in enumerate(user_locations):\n",
        "    for j, location2 in enumerate(user_locations):\n",
        "        distance_matrix[i, j] = geodesic(location1, location2).km\n",
        "\n",
        "# Create an instance of the CollaborativeFilteringModel\n",
        "model = CollaborativeFilteringModel(user_interests, user_locations, institute, max_distance=2.0, K=2)\n",
        "\n",
        "# Example usage\n",
        "target_user_index = 0\n",
        "recommended_users = model.generate_recommendations(target_user_index)\n",
        "\n",
        "print(\"Recommended Users for User\", target_user_index)\n",
        "print(recommended_users)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSdJiK728dvp"
      },
      "outputs": [],
      "source": [
        "# Saving model with Pickle\n",
        "import pickle\n",
        "pickle.dump(model, open('model.pkl', 'wb'))\n",
        "'''\n",
        "Testing purposes\n",
        "pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
        "pickled_model.predict(X_test)\n",
        "\n",
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
